{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77006fa0-d390-404b-aa8e-45c456755053",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# This calculates, summarizes, plots and exports as excel file the image analysis for nuclear import\n",
    "Uses Fiji generated .txt files as input.  \n",
    "Exports results and summarized results as excel file.  \n",
    "Generates violinplots out of all single cells.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddead3e-3c24-4d43-a7cc-e3f87888d3f5",
   "metadata": {},
   "source": [
    "## Initial processing and plotting of individual replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56592047-8e73-4330-a937-b804e8c89509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" open folders sequentially to combine all txt files into one dict, which is used subsequently \"\"\"\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "rawfiles = {}\n",
    "# --- GUI setup---\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "while True:\n",
    "    folder_selected = filedialog.askdirectory(title=\"Choose folder with files, 'Cancel' when you're done, to continue\")\n",
    "    if not folder_selected:  # user cancelled\n",
    "        break # exits whhile loop\n",
    "    \n",
    "    try:\n",
    "        folder_date = re.findall(r'(\\d{6})', folder_selected)[1]\n",
    "    except IndexError:\n",
    "        print(\"No date\")\n",
    "\n",
    "    for filename in sorted(os.listdir(folder_selected)):\n",
    "        print(filename)\n",
    "        file_path = os.path.join(folder_selected, filename)\n",
    "        if filename.startswith(\"._\") or filename.startswith(\"~$\"):\n",
    "            continue\n",
    "        file_name, file_extension = os.path.splitext(filename)\n",
    "\n",
    "        if file_extension == \".txt\":            \n",
    "            file_data = pd.read_csv(file_path, delimiter=\"\\t\", encoding='latin1')\n",
    "        elif file_extension == \".csv\":\n",
    "            file_data = pd.read_csv(file_path, encoding='latin1')\n",
    "        else:\n",
    "            continue\n",
    "        if \"20\" not in file_name:\n",
    "            rawfiles[f\"{folder_date} {file_name}\"] = file_data\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "rawfiles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab3c32-0c96-498f-bdec-199c11046f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "\n",
    "def Filter (rawfiles):\n",
    "    \"\"\"initial processing: remove columns and combine cell & nuc measurements in one row\n",
    "    unprocessed txt files have cell and organelle measurements underneath and not assigned to each other yet\n",
    "    some cells don't have a matching organelle, column names are the same\n",
    "    fiji thresholding information is on bottom two rows and don't contain measurements\n",
    "    remove cells which have 2 nuclei assigned\n",
    "    \"\"\"\n",
    "    files = rawfiles.copy()\n",
    "    #regex = r\"(?P<cond>^\\D*) (?P<time>.*min)_\\d*(?P<col>.*)\" #when name is: condition, timepoint\n",
    "    regex = r\"(?P<cond>.*) (?P<time>\\d* min)_\" #when name is: date, condition, timepoint\n",
    "    filtered_files = {}\n",
    "    for name, data in files.items():\n",
    "        cond = re.search(regex, name).group(\"cond\")\n",
    "        time = re.search(regex, name).group(\"time\")\n",
    "        \n",
    "    #Drop the two bottom rows & the column \"message\"\n",
    "        data = data[:-2]\n",
    "        proc_data = data.drop(columns=['Message'])\n",
    "        \n",
    "    #Calculate total signal (area*mean value) and signal per cell (mean value/ area)\n",
    "        proc_data['Total Signal_Mean'] = proc_data.loc[:,'Area'] * proc_data.loc[:,'Mean']\n",
    "        proc_data['Signal per Cell'] = proc_data.loc[:, 'Mean'] / proc_data.loc[:,\"Area\"]\n",
    "        \n",
    "    #Copy the lower half, the top half, rename columns, make new index from the unnamed column to merge later\n",
    "        half_index = (len(proc_data) // 2) #integer division\n",
    "        top_half = proc_data.iloc[:half_index].drop(columns=[\"Label\"])\n",
    "        top_half.columns = [re.sub(r'^ ', 'Cell_No', col) for col in top_half.columns]\n",
    "        top_half[\"Cell_Label\"] = top_half[\"Cell_No\"]\n",
    "        top_half = top_half.set_index(\"Cell_No\")\n",
    "        bottom_half = proc_data.iloc[half_index:].copy().drop(columns=[\" \"])\n",
    "        bottom_half.columns = [re.sub(r'^Total', 'Nuclear', col) for col in bottom_half.columns]\n",
    "        bottom_half.columns = [re.sub(r'per Cell', 'per Nuc', col) for col in bottom_half.columns]\n",
    "    # Apply regex pattern to non-Nan values, extract the matching object as a string (using .group() ) and make it a number\n",
    "    #and create 2 new columns to filter duplicate values -> remove cells with 2 nuclei\n",
    "        num_pattern = r\"(?<=:0)\\d{3}\"\n",
    "        bottom_half[\"Cell_No\"] = bottom_half[\"Label\"].apply(\n",
    "            lambda x: re.search(num_pattern, x).group() if pd.notna(x) and re.search(num_pattern, x) else None)\\\n",
    "            .astype(\"float\")\n",
    "        filtered_half = bottom_half.drop_duplicates(subset=[\"Cell_No\"], keep=False).set_index(\"Cell_No\").dropna()\n",
    "    \n",
    "    #Merge the two filtered df & drop rows with any NaN values\n",
    "        merged = top_half.join(filtered_half.drop(columns=\"Label\"), how=\"right\", rsuffix=\"_Nuc\")\n",
    "        merged.columns = [re.sub(r'^Mean', 'Px Intst Mean', col) for col in merged.columns]\n",
    "        filtered_files[name] = merged\n",
    "    return filtered_files\n",
    "\n",
    "    \n",
    "def load_bkg ():\n",
    "    \"\"\"upload the NLS-neon background file to subtract the mean bkg pixel intensity from NLS-neon signal\"\"\"\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    bkg_path = filedialog.askopenfilename(title=\"Please select the NLS-neon bkg.xlsx\")\n",
    "    print(\"bkg file:\", bkg_path)\n",
    "    bkg_file = pd.read_excel(bkg_path, sheet_name=\"CombinedSummary\", index_col=[0,1]) #define which columns are the multiindex\n",
    "    root.destroy()\n",
    "    return bkg_file\n",
    "\n",
    "def BkgSub_Calc (filtered):\n",
    "    \"\"\"renames columns according to measured organelle, \n",
    "    subtracts previously determined background signal intensities of each cell and organelle \n",
    "    does not subtract for BFP background files\n",
    "    calculates Mean and Standard Error for each seperate file (field of view)\n",
    "    \"\"\"\n",
    "    \n",
    "    files = filtered.copy()\n",
    "    regex = r\"(?P<date>\\d*) (?P<cond>\\D*) (?P<time>\\d* min)_\" #when name is: date, condition, timepoint\n",
    "    if \"BFP\" not in os.path.basename(file_dir) and \"bkg\" not in os.path.basename(file_dir):\n",
    "    #upload the NLS-neon background file to subtract the background from NLS-neon\n",
    "        bkg_file = load_bkg()\n",
    "    calc_files = {}\n",
    "    for name, file in files.items():\n",
    "        cond = re.search(regex, name).group(\"cond\").split()[0]+\" no estr\"\n",
    "        time = re.search(regex, name).group(\"time\")\n",
    "        if \"BFP\" not in os.path.basename(file_dir) and \"bkg\" not in os.path.basename(file_dir):\n",
    "    #Subtract mean background of each Cell or Nucleus Signal\n",
    "            file[\"Bkg. Sub Px Intst_Cell\"] = file.loc[:,\"Px Intst Mean\"] - bkg_file[\"Combined Mean: Px Intst Mean\"].loc[(cond, time)]\n",
    "            file[\"Bkg. Sub Px Intst_Nuc\"] = file.loc[:,\"Px Intst Mean_Nuc\"] - bkg_file[\"Combined Mean: Px Intst Mean_Nuc\"].loc[(cond, time)]\n",
    "        #all Intensities after Bkg subtraction need to be >=1 to be a valid signal.\n",
    "            file = file[file[\"Bkg. Sub Px Intst_Cell\"] >=1]\n",
    "            file = file[file[\"Bkg. Sub Px Intst_Nuc\"] >=1]\n",
    "            file['Bkg. Sub Total Signal_Mean'] = file.loc[:,'Area'] * file.loc[:,'Bkg. Sub Px Intst_Cell']\n",
    "            file['Bkg. Sub Nuclear Signal_Mean'] = file.loc[:,'Area_Nuc'] * file.loc[:,'Bkg. Sub Px Intst_Nuc']\n",
    "            file[\"Nuclear enrichment\"] = file.loc[:,\"Bkg. Sub Px Intst_Nuc\"]/ file.loc[:,\"Bkg. Sub Px Intst_Cell\"]\n",
    "        #The Nuc signal is part of the whole cell signal, \n",
    "        #cells which Nuc signal is stronger than the WC signal (NE <1) are sorted out\n",
    "            file = file[file[\"Nuclear enrichment\"] >=1]\n",
    "            file['Nuclear Fraction'] = file.loc[:,'Bkg. Sub Nuclear Signal_Mean'] / file.loc[:,'Bkg. Sub Total Signal_Mean']\n",
    "        else:\n",
    "    #Calculate ratio of nucleus intensity and fraction of nucleus signal in the whole cell\n",
    "            file[\"Nuclear enrichment\"] = file.loc[:,\"Px Intst Mean_Nuc\"]/ file.loc[:,\"Px Intst Mean\"]  \n",
    "            file['Nuclear Fraction'] = file.loc[:,'Nuclear Signal_Mean'] / file.loc[:,'Total Signal_Mean']\n",
    "\n",
    "    #Generate new df to store the summarized results\n",
    "    #Calculate Mean of the intensities, Standard Deviation and average cell and nucleus area \n",
    "        summary = pd.DataFrame(columns=[\"\"])\n",
    "        summary.loc[0] = [None]  \n",
    "        summary[\"Mean: Area_Cell\"] = file[\"Area\"].mean()\n",
    "        summary[\"Mean: Area_Nucleus\"] = file[\"Area_Nuc\"].mean()\n",
    "        if \"BFP\" not in os.path.basename(file_dir) and \"bkg\" not in os.path.basename(file_dir):\n",
    "            summary[\"Mean: Bkg. Sub Px Intst_Cell\"] = file[\"Bkg. Sub Px Intst_Cell\"].mean()\n",
    "            summary[\"Mean: Bkg. Sub Px Intst_Nuc\"] = file[\"Bkg. Sub Px Intst_Nuc\"].mean()\n",
    "            summary[\"SEM: Bkg. Sub Px Intst_Cell\"] = file[\"Bkg. Sub Px Intst_Cell\"].sem()\n",
    "            summary[\"SEM: Bkg. Sub Px Intst_Nuc\"] = file[\"Bkg. Sub Px Intst_Nuc\"].sem()\n",
    "        else: \n",
    "            summary[\"Mean: Px Intst_Cell\"] = file[\"Px Intst Mean\"].mean()\n",
    "            summary[\"Mean: Px Intst_Nuc\"] = file[\"Px Intst Mean_Nuc\"].mean()\n",
    "            summary[\"SEM: Px Intst_Cell\"] = file[\"Px Intst Mean\"].sem()\n",
    "            summary[\"SEM: Px Intst_Nuc\"] = file[\"Px Intst Mean_Nuc\"].sem()\n",
    "        \n",
    "        summary[\"Mean: Signal per Cell\"] = file[\"Signal per Cell\"].mean()\n",
    "        summary[\"Mean: Signal per Nucleus\"] = file[\"Signal per Nuc\"].mean()\n",
    "        summary[\"Mean: Nuclear enrichment\"] = file[\"Nuclear enrichment\"].mean()\n",
    "        summary[\"SEM: Nuclear enrichment\"] = file[\"Nuclear enrichment\"].sem()\n",
    "        summary[\"Mean: Nuclear Fraction\"] = file[\"Nuclear Fraction\"].mean()\n",
    "        summary[\"SEM: NucFrac\"] = file[\"Nuclear Fraction\"].sem()\n",
    "        summary[\"# of cells\"] = file[\"Cell_Label\"].count()\n",
    "\n",
    "    #Merge the two dataframes \n",
    "        final = file.reset_index().join(summary.drop(columns=\"\"), how=\"left\")\n",
    "    \n",
    "        calc_files[f\"{name}\"] = final\n",
    "    return calc_files\n",
    "\n",
    "def Summarize (calc_files):\n",
    "    \"\"\"\n",
    "    Combine all single files generated earlier into one final small summary df (\"single_merge\") & a summary of each file (summary)\n",
    "    Distinguishes between bkg file and real file.\n",
    "    Input dfs contain all single cell outputs and a single row with all means and SEM\n",
    "    The function uses multiindexing to combine it, keep every single df and keep it tidy\n",
    "    \"\"\"\n",
    "    \n",
    "    quant_files = copy.deepcopy(calc_files)\n",
    "    regex = r\"(?P<date>\\d*) (?P<cond>\\D*) (?P<time>.*min)_\\d*(?P<col>.*)\" #\\s matches any whitespace character outside of capture group\n",
    "    summary = pd.DataFrame()\n",
    "\n",
    "    for name, file in quant_files.items():\n",
    "        \n",
    "        if file.columns.str.contains(\"Bkg. Sub\").any(): #make the columns a string then look for any match\n",
    "            subset = [\"Mean: Area_Cell\", \"Mean: Area_Nucleus\",\n",
    "                      \"Mean: Bkg. Sub Px Intst_Cell\", \"Mean: Bkg. Sub Px Intst_Nuc\", \n",
    "                      \"SEM: Bkg. Sub Px Intst_Cell\", \"SEM: Bkg. Sub Px Intst_Nuc\",\n",
    "                      \"Mean: Signal per Cell\", \"Mean: Signal per Nucleus\",\n",
    "                      \"Mean: Nuclear enrichment\", \"SEM: Nuclear enrichment\", \n",
    "                      \"Mean: Nuclear Fraction\", \"SEM: NucFrac\",\n",
    "                      \"# of cells\"]\n",
    "            single_subset = [\"Area\", \"Area_Nuc\",\n",
    "                      \"Bkg. Sub Px Intst_Cell\", \"Bkg. Sub Px Intst_Nuc\", \n",
    "                       \"Signal per Cell\", \"Signal per Nuc\",\n",
    "                      \"Nuclear enrichment\",\n",
    "                      \"Nuclear Fraction\",\n",
    "                      \"# of cells\"]\n",
    "        else: \n",
    "            subset = [\"Mean: Area_Cell\", \"Mean: Area_Nucleus\", \n",
    "                      \"Mean: Px Intst_Cell\", \"Mean: Px Intst_Nuc\", \n",
    "                      \"SEM: Px Intst_Cell\", \"SEM: Px Intst_Nuc\",\n",
    "                      \"Mean: Signal per Cell\",\"Mean: Signal per Nucleus\",\n",
    "                      \"Mean: Nuclear enrichment\", \"SEM: Nuclear enrichment\",\n",
    "                      \"Mean: Nuclear Fraction\", \"SEM: NucFrac\",\n",
    "                      \"# of cells\"]\n",
    "            single_subset = [\"Area\", \"Area_Nuc\",\n",
    "                      \"Px Intst Mean\", \"Px Intst Mean_Nuc\", \n",
    "                       \"Signal per Cell\", \"Signal per Nuc\",\n",
    "                      \"Nuclear enrichment\",\n",
    "                      \"Nuclear Fraction\",\n",
    "                      \"# of cells\"]\n",
    "\n",
    "        date = str(re.search(regex, name).group(\"date\"))\n",
    "        cond = re.search(regex, name).group(\"cond\")\n",
    "        time = re.search(regex, name).group(\"time\")\n",
    "        file.columns = [f\"{cond} {time}_{col}\" for col in file.columns] #rename all columns to generate the multiindex\n",
    "       \n",
    "        multiindex = pd.MultiIndex.from_arrays(\n",
    "            arrays=[[date] * len(file.columns),\n",
    "                    [cond] * len(file.columns),\n",
    "                    [time] * len(file.columns),\n",
    "                    [re.search(regex, col).group(\"col\") for col in file.columns]\n",
    "                   ], names=[\"Replicate\", \"Condition\", \"Timepoint\", \"Col\"]\n",
    "        )\n",
    "        file.columns = multiindex\n",
    "        file_stacked = file.stack([\"Replicate\", \"Condition\", \"Timepoint\"], future_stack=True).droplevel(0)\n",
    "        detailed_df = file_stacked[single_subset]\n",
    "    \n",
    "        if summary.empty:\n",
    "            summary = file_stacked[subset].dropna()\n",
    "            detailed_summary = detailed_df\n",
    "        else:\n",
    "            summary = pd.concat([summary, file_stacked[subset].dropna()], axis=0)\n",
    "            detailed_summary = pd.concat([detailed_summary, detailed_df], axis=0)\n",
    "    #subset the df, groupby condition and timepoint, calculate mean or sum, add a prefix to columns\n",
    "\n",
    "    single_mean = detailed_summary.loc[:,[col for col in bkg_df.columns if not \"#\" in col]].groupby([\"Condition\", \"Timepoint\"]).mean().add_prefix(\"Combined Mean: \")\n",
    "\n",
    "    single_sem = detailed_summary.loc[:, [col for col in bkg_df.columns if not any(substring in col for substring in [\"#\", \"Area\", \"Signal\"])]\n",
    "                ].groupby([\"Condition\", \"Timepoint\"]).sem().add_prefix(\"SEM: \")\n",
    "    #sum up all analyzed cells\n",
    "    single_sum = detailed_summary.loc[:,[\"# of cells\"]].groupby([\"Condition\",\"Timepoint\"]).sum().add_prefix(\"Analyzed \")\n",
    "\n",
    "    single_merged = pd.concat([single_mean, single_sem, single_sum], axis=1)\n",
    "    \n",
    "    return summary, single_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40d330-9550-478d-a6d5-6a2400e0171c",
   "metadata": {},
   "source": [
    "## call the above functions to calculate enrichment of NLS-neon in the nucleus and save as excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944f872-f179-4354-b234-665633b8df11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_files = Filter(rawfiles)\n",
    "quant_files = BkgSub_Calc(filtered_files)\n",
    "summary, single_merge = Summarize(quant_files)\n",
    "single_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadabb05-8576-46eb-8057-53476147a0c6",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"generate an excel file with all single files as sheets and summary sheets and save\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "folder_date = re.findall(r'(\\d{6})', file_dir)[1]\n",
    "folder_name = os.path.basename(file_dir)\n",
    "save_path = os.path.join(\n",
    "    os.path.dirname(os.path.dirname(file_dir)), #the parent directory of the last folder\n",
    "    re.search(r\"\\D*(?= Quantification)\", os.path.basename(file_dir))[0] #match NLS-neon etc, \n",
    "    )+\".xlsx\"\n",
    "print(save_path)\n",
    "\n",
    "with pd.ExcelWriter(save_path, engine='openpyxl') as writer: #the file is automatically saved when the \"with\" block is finished\n",
    "    single_merge.to_excel(writer, sheet_name=\"CombinedSummary\", index=True)\n",
    "    summary.to_excel(writer, sheet_name=\"Summary\", index=True)\n",
    "    #Save each individual merged_df to a combined excel file \n",
    "    for name, file in quant_files.items():\n",
    "        #match the first part of the name without the hyperstack and use as excel sheet name\n",
    "        sheet_name = re.search(r\".*(?= hyperstack)\", name).group()\n",
    "        file.to_excel(writer, sheet_name=sheet_name, index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c77f02-5f19-4dc0-804b-4a9259327daa",
   "metadata": {},
   "source": [
    "# Plot the enrichment for each single cell: Violinplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd0b6c-193b-4765-b511-1d5656157edb",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the excel file\n",
    "#put all columns underneath each other in one df\n",
    "#calculate log2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import re\n",
    "\n",
    "def inrow_log2 ():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    data_path = filedialog.askopenfilename(title=\"Please select the .xlsx file to plot\")\n",
    "    print(data_path)\n",
    "    global file_inrow\n",
    "    data_dict = pd.read_excel(data_path, sheet_name=None)\n",
    "    root.destroy()\n",
    "    \n",
    "    file_inrow = pd.DataFrame()\n",
    "    for name, file in data_dict.items():\n",
    "        regex = r\"(?P<cond>\\D*) (?P<time>.*min)_(?P<col>.*)\"\n",
    "        if \"Summary\" not in name:\n",
    "            file = file[[\"Nuclear enrichment\"]]\n",
    "            file[\"log2\"] = np.log2(file)\n",
    "            cond = re.search(regex, name).group(\"cond\").split()[0]\n",
    "            time = re.search(regex, name).group(\"time\")\n",
    "            file.columns = [f\"{cond} {time}_{col}\" for col in file.columns] #rename all columns to generate the multiindex\n",
    "           \n",
    "            multiindex = pd.MultiIndex.from_arrays(\n",
    "                arrays=[[cond] * len(file.columns),\n",
    "                        [time] * len(file.columns),\n",
    "                        [re.search(regex, col).group(\"col\") for col in file.columns]\n",
    "                       ], names=[\"Condition\", \"Timepoint\", \"Col\"]\n",
    "            )\n",
    "            file.columns = multiindex\n",
    "            file_log = file\n",
    "            if file_inrow.empty:\n",
    "                file_inrow= file_log\n",
    "            else:\n",
    "                file_inrow = pd.concat([file_inrow, file_log], axis=0, ignore_index=True)\n",
    "    return data_path, file_inrow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdc7fa-c2f1-4a6b-9c5e-ae83c26b6c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the new df as an excel file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "NLSneon_path, NLSneon = inrow_log2()\n",
    "BFP_path, BFP = inrow_log2()\n",
    "\n",
    "save_path = NLSneon_path.split(\".\")[0]+\"_log2.xlsx\"\n",
    "print(save_path)\n",
    "\n",
    "with pd.ExcelWriter(save_path, engine='openpyxl') as writer: #the file is automatically saved when the \"with\" block is finished\n",
    "    NLSneon.to_excel(writer, sheet_name=\"NLSneon_allcells\", index=True)\n",
    "    BFP.to_excel(writer, sheet_name=\"BFP_allcells\", index=True)\n",
    "NLSneon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877e9a9-05ae-4954-b095-d2a968d2b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" statistics on the 'inrow file' \"\"\"\n",
    "from scipy import stats\n",
    "NLSneon_path, NLSneon = inrow_log2()\n",
    "BFP_path, BFP = inrow_log2()\n",
    "\n",
    "timepoint = input(\"Type the timpoint in xx min\")\n",
    "N_group1 = NLSneon.loc[:, (\"nt\", timepoint, \"Nuclear enrichment\")].dropna()\n",
    "N_group2 = NLSneon.loc[:, (\"DTT\", timepoint, \"Nuclear enrichment\")].dropna()\n",
    "\n",
    "B_group1 = BFP.loc[:, (\"nt\", timepoint, \"Nuclear enrichment\")].dropna()\n",
    "B_group2 = BFP.loc[:, (\"DTT\", timepoint, \"Nuclear enrichment\")].dropna()\n",
    "\n",
    "u_stat, N_p_value = stats.mannwhitneyu(N_group1, N_group2, alternative=\"two-sided\")\n",
    "u_stat, B_p_value = stats.mannwhitneyu(B_group1, B_group2, alternative=\"two-sided\")\n",
    "\n",
    "print(\"NLS-neon:\", N_p_value)\n",
    "print(\"BFP:\", B_p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ebeb9-aefd-4370-8b15-c740fe712290",
   "metadata": {},
   "source": [
    "### the actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597bc8c-5928-47dc-bfdc-b85ff1f1e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "NLSneon_path, NLSneon = inrow_log2()\n",
    "BFP_path, BFP = inrow_log2()\n",
    "\n",
    "save_path = os.path.dirname(NLSneon_path) #the parent directory of the last folder\n",
    "\n",
    "color_map = {\n",
    "    'nt': '#F5F5F5',\n",
    "    'DTT': '#707070',\n",
    "}\n",
    "order = [\"nt\", \"DTT\"]\n",
    "\n",
    "NLSneon = NLSneon.stack([\"Condition\", \"Timepoint\"], future_stack=True).droplevel(0).reset_index().dropna().sort_values(\n",
    "    by=['Condition', 'Timepoint'], key=lambda x: pd.Categorical(x, categories=order))\n",
    "\n",
    "BFP = BFP.stack([\"Condition\", \"Timepoint\"], future_stack=True).droplevel(0).reset_index().dropna().sort_values(\n",
    "    by=['Condition', 'Timepoint'], key=lambda x: pd.Categorical(x, categories=order))\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 9))  # 2 rows, 1 column\n",
    "\n",
    "sns.violinplot(data=NLSneon,\n",
    "               x='Timepoint', y='log2',\n",
    "               ax=axes[0],\n",
    "               hue=\"Condition\", #split=True,\n",
    "               palette=color_map, dodge=True,\n",
    "              inner=\"quart\"\n",
    "              )\n",
    "\n",
    "# Second Plot: \n",
    "sns.violinplot(data=BFP,\n",
    "               x='Timepoint', y='log2',\n",
    "               ax=axes[1],\n",
    "               hue=\"Condition\", #split=True,\n",
    "               palette=color_map, dodge=True,\n",
    "              inner=\"quart\"\n",
    "              )\n",
    "\n",
    "# Customize the first subplot (error bars plot)\n",
    "axes[0].set_title(\"Fold enrichment: NLS-neon\", fontsize=16)\n",
    "axes[0].set_ylabel(\"log2 fold change\", fontsize=12)\n",
    "axes[0].set_yticks(np.arange(-0.5, 3, 0.5)) #ticks from 0.1 to 0.5 with stepsize of 0.1\n",
    "axes[0].set_xticklabels(NLSneon['Timepoint'].unique(), rotation=45)\n",
    "axes[0].legend(frameon=False)\n",
    "\n",
    "# Customize the second subplot (Signal per Cell and Nucleus plot)\n",
    "axes[1].set_title(\"Fold enrichment: BFP\", fontsize=16)\n",
    "axes[1].set_ylabel(\"log2 fold change\", fontsize=12)\n",
    "axes[1].set_yticks(np.arange(-0.5, 3, 0.5))\n",
    "axes[1].set_xticklabels(BFP['Timepoint'].unique(), rotation=45)\n",
    "axes[1].legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "# save the plots\n",
    "\n",
    "saveplots = input(\"Do you want to save the plots? -yes -no\")\n",
    "\n",
    "if saveplots == \"yes\":\n",
    "    plt.savefig(os.path.join(save_path, f\"Import fold change.svg\"), \n",
    "                format='svg', dpi=300, bbox_inches='tight')  # Save with high resolution, crop whitespace around\n",
    "    plt.savefig(os.path.join(save_path, f\"Import fold change.png\"), \n",
    "                dpi=300, bbox_inches='tight')  # Save with high resolution, crop whitespace around\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
